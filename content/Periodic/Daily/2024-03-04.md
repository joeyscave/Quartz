---
date created: 2024-03-04
date modified: 2024-03-05
---
02:15
学习爬虫：基于 Scrapy 库
+ DEBUG: Forbidden by robots.txt
	+ 在项目的settings.py文件中找到或者添加这行代码：`ROBOTSTXT_OBEY = False`，这会让Scrapy忽略robots.txt文件并继续爬取。
+ 设每个用户的数据量为 15B，则一亿用户数据量为 15G